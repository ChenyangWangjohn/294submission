Namespace(save_dir='results', model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', cot=False, no_context=False, rag=False, rag_mind_in_middle=False, middle_to_front_and_end=False, focus_middle=False, n_proc=1, chunk_size=256, change_to_middle=256, seed=42)
INFO 05-16 17:00:42 __init__.py:207] Automatically detected platform cuda.
INFO 05-16 17:00:42 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:00:50 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:00:50 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:00:52 cuda.py:229] Using Flash Attention backend.
INFO 05-16 17:00:52 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:00:58 model_runner.py:1115] Loading model weights took 14.9605 GB
INFO 05-16 17:00:59 worker.py:267] Memory profiling takes 0.87 seconds
INFO 05-16 17:00:59 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:00:59 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.09GiB; PyTorch activation peak memory takes 1.23GiB; the rest of the memory reserved for KV Cache is 55.21GiB.
INFO 05-16 17:00:59 executor_base.py:111] # cuda blocks: 28265, # CPU blocks: 2048
INFO 05-16 17:00:59 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.21x
INFO 05-16 17:01:01 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:01:13 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.26 GiB
INFO 05-16 17:01:13 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 15.10 seconds
INFO 05-16 17:01:23 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:01:23 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:01:23 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:01:24 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:01:31 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:01:32 worker.py:267] Memory profiling takes 0.70 seconds
INFO 05-16 17:01:32 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:01:32 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:01:32 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:01:32 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:01:32 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:01:45 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.08 GiB
INFO 05-16 17:01:45 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.01 seconds
INFO 05-16 17:01:56 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:01:56 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:01:56 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:01:57 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:02:04 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:02:05 worker.py:267] Memory profiling takes 0.70 seconds
INFO 05-16 17:02:05 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:02:05 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:02:05 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:02:05 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:02:05 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:02:18 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.08 GiB
INFO 05-16 17:02:18 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.06 seconds
INFO 05-16 17:02:27 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:02:27 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:02:27 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:02:28 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:02:35 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:02:36 worker.py:267] Memory profiling takes 0.70 seconds
INFO 05-16 17:02:36 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:02:36 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:02:36 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:02:36 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:02:36 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:02:49 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.08 GiB
INFO 05-16 17:02:49 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.02 seconds
INFO 05-16 17:02:57 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:02:57 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:02:57 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:02:58 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:03:05 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:03:06 worker.py:267] Memory profiling takes 0.71 seconds
INFO 05-16 17:03:06 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:03:06 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:03:06 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:03:06 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:03:07 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:03:19 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.08 GiB
INFO 05-16 17:03:20 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.05 seconds
WARNING 05-16 17:03:28 scheduler.py:1091] Input prompt (8193 tokens) is too long and exceeds limit of 8192
INFO 05-16 17:03:32 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:03:32 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:03:32 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:03:33 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:03:41 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:03:41 worker.py:267] Memory profiling takes 0.70 seconds
INFO 05-16 17:03:41 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:03:41 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:03:42 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:03:42 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:03:42 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:03:55 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.08 GiB
INFO 05-16 17:03:55 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.11 seconds
INFO 05-16 17:04:03 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:04:03 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:04:03 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:04:04 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:04:11 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:04:12 worker.py:267] Memory profiling takes 0.70 seconds
INFO 05-16 17:04:12 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:04:12 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:04:12 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:04:12 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:04:13 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:04:25 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.08 GiB
INFO 05-16 17:04:25 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.06 seconds
INFO 05-16 17:04:32 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:04:32 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:04:32 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:04:33 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:04:40 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:04:41 worker.py:267] Memory profiling takes 0.71 seconds
INFO 05-16 17:04:41 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:04:41 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:04:41 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:04:41 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:04:42 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:04:54 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.08 GiB
INFO 05-16 17:04:54 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.17 seconds
WARNING 05-16 17:04:58 scheduler.py:1091] Input prompt (8193 tokens) is too long and exceeds limit of 8192
INFO 05-16 17:05:02 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:05:02 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:05:02 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:05:03 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:05:10 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:05:11 worker.py:267] Memory profiling takes 0.70 seconds
INFO 05-16 17:05:11 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:05:11 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:05:11 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:05:11 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:05:12 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:05:24 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.08 GiB
INFO 05-16 17:05:24 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.11 seconds
INFO 05-16 17:05:34 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:05:34 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:05:34 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:05:35 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:05:42 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:05:43 worker.py:267] Memory profiling takes 0.71 seconds
INFO 05-16 17:05:43 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:05:43 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:05:43 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:05:43 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:05:44 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:05:56 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.08 GiB
INFO 05-16 17:05:56 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.15 seconds
WARNING 05-16 17:06:01 scheduler.py:1091] Input prompt (8193 tokens) is too long and exceeds limit of 8192
INFO 05-16 17:06:05 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:06:05 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:06:05 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:06:06 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:06:13 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:06:14 worker.py:267] Memory profiling takes 0.71 seconds
INFO 05-16 17:06:14 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:06:14 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:06:14 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:06:14 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:06:14 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:06:27 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.08 GiB
INFO 05-16 17:06:27 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.08 seconds
INFO 05-16 17:06:34 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:06:34 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:06:34 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:06:35 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:06:42 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:06:43 worker.py:267] Memory profiling takes 0.70 seconds
INFO 05-16 17:06:43 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:06:43 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:06:43 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:06:43 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:06:43 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:06:56 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.08 GiB
INFO 05-16 17:06:56 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.05 seconds
INFO 05-16 17:07:03 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:07:03 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:07:03 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:07:04 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:07:11 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:07:12 worker.py:267] Memory profiling takes 0.70 seconds
INFO 05-16 17:07:12 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:07:12 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:07:12 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:07:12 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:07:12 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:07:25 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.08 GiB
INFO 05-16 17:07:25 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.09 seconds
INFO 05-16 17:07:34 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:07:34 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:07:34 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:07:34 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:07:41 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:07:42 worker.py:267] Memory profiling takes 0.70 seconds
INFO 05-16 17:07:42 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:07:42 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:07:42 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:07:42 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:07:43 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:07:56 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.08 GiB
INFO 05-16 17:07:56 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.38 seconds
INFO 05-16 17:08:04 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:08:04 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:08:04 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:08:05 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:08:12 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:08:13 worker.py:267] Memory profiling takes 0.71 seconds
INFO 05-16 17:08:13 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:08:13 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:08:13 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:08:13 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:08:13 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:08:26 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.08 GiB
INFO 05-16 17:08:26 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.10 seconds
INFO 05-16 17:08:35 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:08:35 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:08:35 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:08:36 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:08:43 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:08:43 worker.py:267] Memory profiling takes 0.70 seconds
INFO 05-16 17:08:43 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:08:43 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:08:44 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:08:44 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:08:44 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:08:57 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.08 GiB
INFO 05-16 17:08:57 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.20 seconds
INFO 05-16 17:09:06 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:09:06 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:09:06 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:09:07 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:09:14 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:09:15 worker.py:267] Memory profiling takes 0.70 seconds
INFO 05-16 17:09:15 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:09:15 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:09:15 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:09:15 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:09:15 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:09:28 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.08 GiB
INFO 05-16 17:09:28 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.04 seconds
INFO 05-16 17:09:38 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:09:38 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:09:38 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:09:39 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:09:46 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:09:46 worker.py:267] Memory profiling takes 0.70 seconds
INFO 05-16 17:09:46 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:09:46 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:09:47 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:09:47 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:09:47 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:10:00 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.08 GiB
INFO 05-16 17:10:00 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.13 seconds
INFO 05-16 17:10:21 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:10:21 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:10:21 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:10:22 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:10:27 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:10:28 worker.py:267] Memory profiling takes 0.70 seconds
INFO 05-16 17:10:28 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:10:28 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:10:28 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:10:28 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:10:28 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:10:41 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.08 GiB
INFO 05-16 17:10:41 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.09 seconds
INFO 05-16 17:10:51 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:10:51 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:10:51 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:10:52 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:10:57 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:10:58 worker.py:267] Memory profiling takes 0.70 seconds
INFO 05-16 17:10:58 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:10:58 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:10:58 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:10:58 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:10:58 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:11:11 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.08 GiB
INFO 05-16 17:11:11 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.06 seconds
INFO 05-16 17:11:22 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:11:22 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:11:22 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:11:22 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:11:28 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:11:29 worker.py:267] Memory profiling takes 0.70 seconds
INFO 05-16 17:11:29 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:11:29 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:11:29 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:11:29 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:11:29 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:11:42 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.08 GiB
INFO 05-16 17:11:42 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.07 seconds
INFO 05-16 17:11:49 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:11:49 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:11:49 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:11:50 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:11:55 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:11:56 worker.py:267] Memory profiling takes 0.70 seconds
INFO 05-16 17:11:56 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:11:56 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:11:56 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:11:56 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:11:57 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:12:09 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.08 GiB
INFO 05-16 17:12:09 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.00 seconds
INFO 05-16 17:12:18 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:12:18 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:12:18 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:12:19 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:12:26 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:12:27 worker.py:267] Memory profiling takes 0.70 seconds
INFO 05-16 17:12:27 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:12:27 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:12:27 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:12:27 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:12:27 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:12:40 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.08 GiB
INFO 05-16 17:12:40 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 13.98 seconds
INFO 05-16 17:12:48 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:12:48 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:12:48 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:12:49 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:12:56 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:12:56 worker.py:267] Memory profiling takes 0.71 seconds
INFO 05-16 17:12:56 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:12:56 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:12:57 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:12:57 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:12:57 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:13:10 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.08 GiB
INFO 05-16 17:13:10 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.29 seconds
INFO 05-16 17:13:19 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:13:19 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:13:19 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:13:20 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:13:27 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:13:28 worker.py:267] Memory profiling takes 0.70 seconds
INFO 05-16 17:13:28 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:13:28 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:13:28 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:13:28 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:13:28 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:13:41 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.08 GiB
INFO 05-16 17:13:41 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.05 seconds
INFO 05-16 17:13:51 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:13:51 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:13:51 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:13:52 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:13:59 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:14:00 worker.py:267] Memory profiling takes 0.71 seconds
INFO 05-16 17:14:00 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:14:00 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:14:00 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:14:00 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:14:00 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:14:13 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.08 GiB
INFO 05-16 17:14:13 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.13 seconds
INFO 05-16 17:14:21 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:14:21 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:14:21 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:14:22 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:14:29 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:14:30 worker.py:267] Memory profiling takes 0.70 seconds
INFO 05-16 17:14:30 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:14:30 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:14:30 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:14:30 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:14:30 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:14:43 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.08 GiB
INFO 05-16 17:14:43 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.05 seconds
INFO 05-16 17:14:51 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:14:51 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:14:51 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:14:52 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:14:59 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:15:00 worker.py:267] Memory profiling takes 0.70 seconds
INFO 05-16 17:15:00 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:15:00 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:15:00 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:15:00 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:15:01 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:15:13 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.08 GiB
INFO 05-16 17:15:13 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.03 seconds
INFO 05-16 17:15:26 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:15:26 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:15:26 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:15:27 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:15:32 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:15:33 worker.py:267] Memory profiling takes 0.70 seconds
INFO 05-16 17:15:33 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:15:33 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:15:33 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:15:33 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:15:34 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:15:46 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.08 GiB
INFO 05-16 17:15:46 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.12 seconds
WARNING 05-16 17:15:51 scheduler.py:1091] Input prompt (8193 tokens) is too long and exceeds limit of 8192
INFO 05-16 17:15:54 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:15:54 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:15:54 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:15:55 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:16:00 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:16:01 worker.py:267] Memory profiling takes 0.71 seconds
INFO 05-16 17:16:01 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:16:01 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:16:01 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:16:01 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:16:01 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:16:14 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.08 GiB
INFO 05-16 17:16:14 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.12 seconds
INFO 05-16 17:16:22 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:16:22 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:16:22 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:16:22 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:16:29 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:16:30 worker.py:267] Memory profiling takes 0.71 seconds
INFO 05-16 17:16:30 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:16:30 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:16:30 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:16:30 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:16:31 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:16:44 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.08 GiB
INFO 05-16 17:16:44 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.11 seconds
INFO 05-16 17:16:51 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:16:51 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:16:51 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:16:52 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:16:59 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:17:00 worker.py:267] Memory profiling takes 0.71 seconds
INFO 05-16 17:17:00 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:17:00 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:17:00 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:17:00 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:17:00 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:17:13 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.06 GiB
INFO 05-16 17:17:13 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.10 seconds
INFO 05-16 17:17:23 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:17:23 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:17:23 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:17:24 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:17:31 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:17:32 worker.py:267] Memory profiling takes 0.71 seconds
INFO 05-16 17:17:32 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:17:32 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:17:32 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:17:32 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:17:32 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:17:45 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.08 GiB
INFO 05-16 17:17:45 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.13 seconds
INFO 05-16 17:18:05 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:18:05 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:18:05 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:18:06 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:18:13 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:18:14 worker.py:267] Memory profiling takes 0.71 seconds
INFO 05-16 17:18:14 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:18:14 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:18:14 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:18:14 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:18:15 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:18:27 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.06 GiB
INFO 05-16 17:18:27 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.10 seconds
INFO 05-16 17:18:36 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:18:36 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:18:36 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:18:37 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:18:42 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:18:43 worker.py:267] Memory profiling takes 0.70 seconds
INFO 05-16 17:18:43 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:18:43 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:18:43 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:18:43 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:18:43 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:18:56 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.06 GiB
INFO 05-16 17:18:56 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.16 seconds
INFO 05-16 17:19:04 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:19:04 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:19:04 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:19:05 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:19:12 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:19:13 worker.py:267] Memory profiling takes 0.71 seconds
INFO 05-16 17:19:13 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:19:13 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:19:13 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:19:13 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:19:13 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:19:26 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.06 GiB
INFO 05-16 17:19:26 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.08 seconds
INFO 05-16 17:19:34 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:19:34 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:19:34 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:19:35 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:19:41 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:19:42 worker.py:267] Memory profiling takes 0.70 seconds
INFO 05-16 17:19:42 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:19:42 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:19:42 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:19:42 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:19:42 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:19:55 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.06 GiB
INFO 05-16 17:19:55 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.17 seconds
INFO 05-16 17:20:02 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:20:02 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:20:02 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:20:02 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:20:09 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:20:10 worker.py:267] Memory profiling takes 0.71 seconds
INFO 05-16 17:20:10 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:20:10 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:20:10 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:20:10 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:20:11 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:20:23 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.06 GiB
INFO 05-16 17:20:23 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.12 seconds
INFO 05-16 17:20:32 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:20:32 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:20:32 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:20:33 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:20:38 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:20:39 worker.py:267] Memory profiling takes 0.71 seconds
INFO 05-16 17:20:39 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:20:39 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:20:39 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:20:39 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:20:39 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:20:52 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.06 GiB
INFO 05-16 17:20:52 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.20 seconds
INFO 05-16 17:21:00 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:21:00 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:21:00 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:21:01 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:21:06 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:21:07 worker.py:267] Memory profiling takes 0.71 seconds
INFO 05-16 17:21:07 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:21:07 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:21:07 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:21:07 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:21:07 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:21:20 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.06 GiB
INFO 05-16 17:21:20 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.13 seconds
WARNING 05-16 17:21:25 scheduler.py:1091] Input prompt (8193 tokens) is too long and exceeds limit of 8192
INFO 05-16 17:21:29 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:21:29 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:21:29 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:21:30 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:21:36 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:21:36 worker.py:267] Memory profiling takes 0.71 seconds
INFO 05-16 17:21:36 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:21:36 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:21:37 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:21:37 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:21:37 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:21:50 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.06 GiB
INFO 05-16 17:21:50 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.08 seconds
INFO 05-16 17:21:57 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:21:57 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:21:57 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:21:58 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:22:03 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:22:04 worker.py:267] Memory profiling takes 0.71 seconds
INFO 05-16 17:22:04 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:22:04 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:22:04 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:22:04 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:22:04 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:22:17 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.06 GiB
INFO 05-16 17:22:17 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.11 seconds
INFO 05-16 17:22:29 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:22:29 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:22:29 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:22:29 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:22:36 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:22:37 worker.py:267] Memory profiling takes 0.71 seconds
INFO 05-16 17:22:37 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:22:37 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:22:37 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:22:37 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:22:38 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:22:50 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.06 GiB
INFO 05-16 17:22:50 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.01 seconds
INFO 05-16 17:22:59 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:22:59 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:22:59 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:23:00 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:23:07 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:23:08 worker.py:267] Memory profiling takes 0.70 seconds
INFO 05-16 17:23:08 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:23:08 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:23:08 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:23:08 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:23:09 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:23:22 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.06 GiB
INFO 05-16 17:23:22 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.09 seconds
INFO 05-16 17:23:32 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:23:32 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:23:32 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:23:33 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:23:40 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:23:41 worker.py:267] Memory profiling takes 0.71 seconds
INFO 05-16 17:23:41 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:23:41 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:23:41 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:23:41 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:23:42 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:23:54 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.06 GiB
INFO 05-16 17:23:54 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.16 seconds
INFO 05-16 17:24:06 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:24:06 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:24:06 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:24:07 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:24:14 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:24:15 worker.py:267] Memory profiling takes 0.70 seconds
INFO 05-16 17:24:15 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:24:15 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:24:15 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:24:15 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:24:15 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:24:28 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.06 GiB
INFO 05-16 17:24:28 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.13 seconds
INFO 05-16 17:24:36 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:24:36 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:24:36 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:24:36 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:24:43 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:24:44 worker.py:267] Memory profiling takes 0.70 seconds
INFO 05-16 17:24:44 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:24:44 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:24:45 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:24:45 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:24:45 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:24:58 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.06 GiB
INFO 05-16 17:24:58 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.23 seconds
INFO 05-16 17:25:29 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:25:29 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:25:29 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:25:30 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:25:37 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:25:38 worker.py:267] Memory profiling takes 0.70 seconds
INFO 05-16 17:25:38 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:25:38 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:25:38 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:25:38 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:25:38 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:25:51 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.06 GiB
INFO 05-16 17:25:51 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.07 seconds
INFO 05-16 17:25:58 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:25:58 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:25:58 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:25:59 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:26:06 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:26:07 worker.py:267] Memory profiling takes 0.71 seconds
INFO 05-16 17:26:07 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:26:07 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:26:07 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:26:07 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:26:08 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:26:20 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.06 GiB
INFO 05-16 17:26:20 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.02 seconds
INFO 05-16 17:26:30 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:26:30 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:26:30 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:26:31 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:26:38 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:26:39 worker.py:267] Memory profiling takes 0.70 seconds
INFO 05-16 17:26:39 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:26:39 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:26:39 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:26:39 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:26:39 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:26:52 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.06 GiB
INFO 05-16 17:26:52 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.17 seconds
INFO 05-16 17:27:02 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:27:02 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:27:02 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:27:03 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:27:08 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:27:09 worker.py:267] Memory profiling takes 0.71 seconds
INFO 05-16 17:27:09 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:27:09 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:27:09 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:27:09 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:27:10 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:27:23 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.06 GiB
INFO 05-16 17:27:23 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.12 seconds
INFO 05-16 17:27:34 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:27:34 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:27:34 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:27:35 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:27:40 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:27:41 worker.py:267] Memory profiling takes 0.71 seconds
INFO 05-16 17:27:41 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:27:41 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:27:42 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:27:42 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:27:42 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:27:55 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.06 GiB
INFO 05-16 17:27:55 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.33 seconds
INFO 05-16 17:28:07 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:28:07 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:28:07 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:28:08 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:28:13 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:28:14 worker.py:267] Memory profiling takes 0.70 seconds
INFO 05-16 17:28:14 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:28:14 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:28:14 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:28:14 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:28:14 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:28:27 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.06 GiB
INFO 05-16 17:28:27 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.07 seconds
INFO 05-16 17:28:36 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:28:36 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:28:36 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:28:37 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:28:42 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:28:43 worker.py:267] Memory profiling takes 0.71 seconds
INFO 05-16 17:28:43 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:28:43 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:28:43 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:28:43 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:28:44 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:28:57 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.06 GiB
INFO 05-16 17:28:57 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.15 seconds
INFO 05-16 17:29:09 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:29:09 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:29:09 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:29:10 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:29:15 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:29:16 worker.py:267] Memory profiling takes 0.71 seconds
INFO 05-16 17:29:16 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:29:16 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:29:16 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:29:16 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:29:16 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:29:29 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.06 GiB
INFO 05-16 17:29:29 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.14 seconds
INFO 05-16 17:29:40 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:29:40 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:29:40 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:29:41 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:29:48 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:29:49 worker.py:267] Memory profiling takes 0.71 seconds
INFO 05-16 17:29:49 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:29:49 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:29:49 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:29:49 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:29:49 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:30:02 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.06 GiB
INFO 05-16 17:30:02 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.19 seconds
WARNING 05-16 17:30:07 scheduler.py:1091] Input prompt (8193 tokens) is too long and exceeds limit of 8192
INFO 05-16 17:30:11 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:30:11 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:30:11 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:30:12 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:30:17 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:30:18 worker.py:267] Memory profiling takes 0.71 seconds
INFO 05-16 17:30:18 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:30:18 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:30:18 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:30:18 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:30:18 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:30:31 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.06 GiB
INFO 05-16 17:30:31 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.10 seconds
INFO 05-16 17:30:53 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:30:53 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:30:53 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:30:54 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:31:01 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:31:02 worker.py:267] Memory profiling takes 0.70 seconds
INFO 05-16 17:31:02 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:31:02 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:31:02 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:31:02 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:31:02 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:31:15 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.06 GiB
INFO 05-16 17:31:15 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.17 seconds
WARNING 05-16 17:31:22 scheduler.py:1091] Input prompt (8193 tokens) is too long and exceeds limit of 8192
INFO 05-16 17:31:23 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:31:23 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:31:23 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:31:24 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:31:31 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:31:32 worker.py:267] Memory profiling takes 0.71 seconds
INFO 05-16 17:31:32 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:31:32 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:31:32 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:31:32 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:31:32 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:31:45 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.06 GiB
INFO 05-16 17:31:45 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.15 seconds
INFO 05-16 17:31:59 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:31:59 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:31:59 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:32:00 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:32:07 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:32:08 worker.py:267] Memory profiling takes 0.70 seconds
INFO 05-16 17:32:08 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:32:08 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:32:08 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:32:08 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:32:09 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:32:21 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.06 GiB
INFO 05-16 17:32:21 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.16 seconds
INFO 05-16 17:32:29 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:32:29 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:32:29 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:32:30 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:32:37 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:32:37 worker.py:267] Memory profiling takes 0.70 seconds
INFO 05-16 17:32:37 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:32:37 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:32:38 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:32:38 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:32:38 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:32:51 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.06 GiB
INFO 05-16 17:32:51 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.17 seconds
INFO 05-16 17:33:02 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:33:02 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:33:02 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:33:03 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:33:10 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:33:11 worker.py:267] Memory profiling takes 0.71 seconds
INFO 05-16 17:33:11 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:33:11 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:33:11 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:33:11 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:33:11 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:33:24 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.06 GiB
INFO 05-16 17:33:24 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.19 seconds
INFO 05-16 17:33:32 config.py:2444] Downcasting torch.float32 to torch.float16.
INFO 05-16 17:33:32 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-16 17:33:32 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', speculative_config=None, tokenizer='/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 05-16 17:33:33 model_runner.py:1110] Starting to load model /data/xuandong_zhao/mnt/kefengduan/Minding_the_Middle/John/model/merged_model...
INFO 05-16 17:33:40 model_runner.py:1115] Loading model weights took 14.9586 GB
INFO 05-16 17:33:40 worker.py:267] Memory profiling takes 0.70 seconds
INFO 05-16 17:33:40 worker.py:267] the current vLLM instance can use total_gpu_memory (79.44GiB) x gpu_memory_utilization (0.90) = 71.49GiB
INFO 05-16 17:33:40 worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.22GiB; the rest of the memory reserved for KV Cache is 55.31GiB.
INFO 05-16 17:33:41 executor_base.py:111] # cuda blocks: 28317, # CPU blocks: 2048
INFO 05-16 17:33:41 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 55.31x
INFO 05-16 17:33:41 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 17:33:54 model_runner.py:1562] Graph capturing finished in 13 secs, took 0.06 GiB
INFO 05-16 17:33:54 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.27 seconds
